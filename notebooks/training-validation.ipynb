{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8526c5c",
   "metadata": {},
   "source": [
    "# Treinamento & Validação\n",
    "Esse **Jupyter Notebook** tem como objetivo treinar modelos de *Machine Learning* com uma ou mais *features* e verificar quão bem esses modelos estão aprendendo com base na métrica de validação - [Erro Médio Absoluto](https://en.wikipedia.org/wiki/Mean_absolute_error)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f68e36",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c734791",
   "metadata": {},
   "source": [
    "# Classe \"Training\"\n",
    "Como um dos requisitos da **GRIA** para o desafio era que os códigos fossem reaproveitados e documentados. Para satisfazer esses requisitos vamos criar a classe **Training** que vai ser responsável pelo processo de treinar nossos dados em vários modelos diferentes e metrifica-los."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d81a2cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import floor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "class Training:\n",
    "\n",
    "  def split_data(self, x, y):\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "    return x_train, x_valid, y_train, y_valid\n",
    "\n",
    "\n",
    "  def linear_regression(self, x_train, y_train, x_valid_test, predict=False, model_name=None):\n",
    "    model = LinearRegression() # Instance.\n",
    "    model.fit(x_train, y_train) # Training.\n",
    "    # Save model process.\n",
    "    if model_name is not None:\n",
    "      joblib.dump(\n",
    "        value=model,\n",
    "        filename=f\"../resources/load/{model_name}.pkl\"\n",
    "      )\n",
    "      print(\"Model saved!\")\n",
    "    # Predict process.\n",
    "    if predict is True:\n",
    "      salaries_predicted = pd.DataFrame(model.predict(x_valid_test), columns=[\"SalaryNormalized\"])\n",
    "      return salaries_predicted\n",
    "\n",
    "\n",
    "  def ridge_regression(self, x_train, y_train, x_valid_test, predict=False, model_name=None):\n",
    "    model = Ridge(alpha=1.0) # Alpha = Learning Rate.\n",
    "    model.fit(x_train, y_train) # Training.\n",
    "    # Save model process.\n",
    "    if model_name is not None:\n",
    "      joblib.dump(\n",
    "        value=model,\n",
    "        filename=f\"../resources/load/{model_name}.pkl\"\n",
    "      )\n",
    "      print(\"Model saved!\")\n",
    "    # Predict process.\n",
    "    if predict is True:\n",
    "      salaries_predicted = pd.DataFrame(model.predict(x_valid_test), columns=[\"SalaryNormalized\"])\n",
    "      return salaries_predicted\n",
    "\n",
    "\n",
    "  def lasso_regression(self, x_train, y_train, x_valid_test, predict=False, model_name=None):\n",
    "    model = Lasso(alpha=10, max_iter=1000, tol=0.1)\n",
    "    model.fit(x_train, y_train) # Training.\n",
    "    # Save model process.\n",
    "    if model_name is not None:\n",
    "      joblib.dump(\n",
    "        value=model,\n",
    "        filename=f\"../resources/load/{model_name}.pkl\"\n",
    "      )\n",
    "      print(\"Model saved!\")\n",
    "    # Predict process.\n",
    "    if predict is True:\n",
    "      salaries_predicted = pd.DataFrame(model.predict(x_valid_test), columns=[\"SalaryNormalized\"])\n",
    "      return salaries_predicted\n",
    "\n",
    "\n",
    "  def elasticnet_regression(self, x_train, y_train, x_valid_test, predict=False, model_name=None):\n",
    "    model = ElasticNet(alpha=1, l1_ratio=0.5, tol=0.3)\n",
    "    model.fit(x_train, y_train) # Training.\n",
    "    # Save model process.\n",
    "    if model_name is not None:\n",
    "      joblib.dump(\n",
    "        value=model,\n",
    "        filename=f\"../resources/load/{model_name}.pkl\"\n",
    "      )\n",
    "      print(\"Model saved!\")\n",
    "    # Predict process.\n",
    "    if predict is True:\n",
    "      salaries_predicted = pd.DataFrame(model.predict(x_valid_test), columns=[\"SalaryNormalized\"])\n",
    "      return salaries_predicted\n",
    "\n",
    "\n",
    "  def random_forest_regressor(self, x_train, y_train, x_valid_test, predict=False, model_name=None):\n",
    "    model = RandomForestRegressor(n_jobs=-1) # Instance.\n",
    "    model.fit(x_train, np.ravel(y_train)) # Training.\n",
    "    # Save model process.\n",
    "    if model_name is not None:\n",
    "      joblib.dump(\n",
    "        value=model,\n",
    "        filename=f\"../resources/load/{model_name}.pkl\"\n",
    "      )\n",
    "      print(\"Model saved!\")\n",
    "    # Predict process.\n",
    "    if predict is True:\n",
    "      salaries_predicted = pd.DataFrame(model.predict(x_valid_test), columns=[\"SalaryNormalized\"])\n",
    "      return salaries_predicted\n",
    "\n",
    "\n",
    "  def get_mae_scores(self, x, y):\n",
    "\n",
    "    # KFold instance -  # shuffle=True, Shuffle (embaralhar) the data.\n",
    "    kfold = KFold(\n",
    "      n_splits=10,\n",
    "      shuffle=True\n",
    "    )\n",
    "\n",
    "    # Models instances.\n",
    "    randomForestRegressor = RandomForestRegressor(n_jobs=-1)\n",
    "    linearRegression      = LinearRegression()\n",
    "    elasticNet            = ElasticNet()\n",
    "    ridge                 = Ridge()\n",
    "    lasso                 = Lasso()\n",
    "\n",
    "    # Apply cross-validation with KFold for all models.\n",
    "    randomForestRegressor_result = abs(cross_val_score(randomForestRegressor, x, y, cv = kfold, scoring='neg_mean_absolute_error'))\n",
    "    linearRegression_result      = abs(cross_val_score(linearRegression, x, y, cv = kfold, scoring='neg_mean_absolute_error'))\n",
    "    elasticNet_result            = abs(cross_val_score(elasticNet, x, y, cv = kfold, scoring='neg_mean_absolute_error'))\n",
    "    ridge_result                 = abs(cross_val_score(ridge, x, y, cv = kfold, scoring='neg_mean_absolute_error'))\n",
    "    lasso_result                 = abs(cross_val_score(lasso, x, y, cv = kfold, scoring='neg_mean_absolute_error'))\n",
    "\n",
    "    # Create a dictionary to store the Models.\n",
    "    dic_models = {\n",
    "      \"randomForestRegressor\": randomForestRegressor_result.mean(),\n",
    "      \"LinearRegression\": linearRegression_result.mean(),\n",
    "      \"ElasticNet\": elasticNet_result.mean(),\n",
    "      \"Ridge\": ridge_result.mean(),\n",
    "      \"Lasso\": lasso_result.mean()\n",
    "    }\n",
    "    bestModel = min(dic_models, key=dic_models.get) # Select the best model.\n",
    "\n",
    "    print(\"MAE for Random Forest Regressor: {0}\\nMAE for Linear Regression: {1}\\nMAE for Ridge (L2) Regression: {2}\\nMAE for Lasso (L1) Regression: {3}\\nMAE for Elastic Net (L2 + L1) Regression: {4}\".format(randomForestRegressor_result.mean(), linearRegression_result.mean(), elasticNet_result.mean(), ridge_result.mean(), lasso_result.mean()))\n",
    "    print(\"The best model is {0} with MAE value: {1}\".format(bestModel, dic_models[bestModel]))\n",
    "\n",
    "\n",
    "  def create_train_sizes(self, x, cv):\n",
    "    train_sizes = [1] # Start train_size with 1 element.\n",
    "    count_while = 1 # While control.\n",
    "    div_train_sizes = floor(x.shape[0]/2) #\n",
    "    while count_while < cv:\n",
    "      train_sizes.insert(1, div_train_sizes) # Always add train_size in to index=1, index 0 always is 1.\n",
    "      div_train_sizes = floor(div_train_sizes/2) # Set new value to div_train_sizes\n",
    "      count_while += 1 # While increment.\n",
    "    return train_sizes\n",
    "\n",
    "\n",
    "  def create_learning_curves(self, x=None, y=None, estimator=None, cv=5, save=None):\n",
    "\n",
    "    # Check X, y variables.\n",
    "    if x is None:\n",
    "      return print(\"Please, enter X variables!\")\n",
    "    elif y is None:\n",
    "      return print(\"Please, enter target (Y) variable!\")\n",
    "    \n",
    "    # Check estimator before create Learning Curves.\n",
    "    if estimator is None:\n",
    "      return print(\"Please, enter your estimator!\")\n",
    "    else:\n",
    "      try:\n",
    "        estimator = estimator()\n",
    "      except NameError:\n",
    "        print(\"Invalid estimator!\")\n",
    "      else:\n",
    "        # Get train sizes.\n",
    "        train_sizes = self.create_train_sizes(x, cv)\n",
    "        # Get Learning Curve statistics.\n",
    "        train_sizes, train_scores, validation_scores = learning_curve(\n",
    "          estimator = estimator,\n",
    "          X = x,\n",
    "          y = y,\n",
    "          train_sizes = train_sizes,\n",
    "          cv = cv,\n",
    "          scoring = 'neg_mean_squared_error',\n",
    "          shuffle=True\n",
    "        )\n",
    "        # Get mean statistics.\n",
    "        train_scores_mean = -train_scores.mean(axis = 1)\n",
    "        validation_scores_mean = -validation_scores.mean(axis = 1)\n",
    "        # Display statistics.\n",
    "        print(\"train_sizes: \", train_sizes)\n",
    "        print('\\n', '-' * 70) # Estamos multiplicando o caractere '-' por 70, ou seja, uma linha tracejada.   \n",
    "        print('Training scores:\\n\\n', train_scores)\n",
    "        print('\\nValidation scores:\\n\\n', validation_scores)\n",
    "        print('\\n', '-' * 70)  \n",
    "        print('\\nMean training scores:\\n', pd.Series(train_scores_mean, index = train_sizes))\n",
    "        print('\\nMean validation scores:\\n',pd.Series(validation_scores_mean, index = train_sizes))\n",
    "        # Create a plot.\n",
    "        if save is None:\n",
    "          plt.figure(figsize=(10, 7))\n",
    "          plt.style.use('seaborn')\n",
    "          plt.plot(train_sizes, train_scores_mean, marker='o', label = 'Training error')\n",
    "          plt.plot(train_sizes, validation_scores_mean, marker='o', label = 'Validation error')\n",
    "          plt.ylabel('MAE', fontsize = 14)\n",
    "          plt.xlabel('Training set size', fontsize = 14)\n",
    "          plt.title('Learning curves for a ' + str(estimator).split('(')[0] + ' model', fontsize = 18, y = 1.03)\n",
    "          plt.legend()\n",
    "          plt.show()\n",
    "        else:\n",
    "          plt.figure(figsize=(10, 7))\n",
    "          plt.style.use('seaborn')\n",
    "          plt.plot(train_sizes, train_scores_mean, marker='o', label = 'Training error')\n",
    "          plt.plot(train_sizes, validation_scores_mean, marker='o', label = 'Validation error')\n",
    "          plt.ylabel('MAE', fontsize = 14)\n",
    "          plt.xlabel('Training set size', fontsize = 14)\n",
    "          plt.title('Learning curves for a ' + str(estimator).split('(')[0] + ' model', fontsize = 18, y = 1.03)\n",
    "          plt.legend()\n",
    "          plt.savefig(f\"../resources/load/{save}.png\", format='png')\n",
    "          plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fd58f8",
   "metadata": {},
   "source": [
    "Agora vamos criar uma instância da classe **Training**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa9dd9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training instance.\n",
    "training = Training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9d7b30",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d136f0",
   "metadata": {},
   "source": [
    "# 01 - Preparando o Ambiente e importando módulos externos\n",
    "Nessa etapa vamos preparar os dados e o ambiente (jupyter notebook) e importar o módulo externo **preprocessing.py**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f811e00d",
   "metadata": {},
   "source": [
    "## 01 - Baixando as Bibliotecas necessárias\n",
    "Inicialmente vamos baixar as bibliotecas necessárias para nossa análise (Eu já tenho todas baixadas no meu ambiente virtual, mas vocês podem remover o comentário e baixar para sua máquina local ou Ambiente Virtual)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95c93f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade -r ../requirements.txt --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b95159",
   "metadata": {},
   "source": [
    "## 01.2 - Importando o módulo \"Preprocessing\"\n",
    "Nós também vamos utilizar o módulo **\"Preprocessing\"** que foi criado na etapa de *Pré-Processamento*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e97fd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../src/preprocessing.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01c2e3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = Preprocessing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53632319",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17a5585",
   "metadata": {},
   "source": [
    "# 02 - Treinando & Validando os Loads\n",
    "> Na parte de **Treinamento & Validação** nós vamos utilizar as colunas (features) já Pré-Processadas em cada **Load** para treinar vários modelos de Regressão e tentar encontrar o que nós dar o melhor resultado (performance) de acordo com os dados passados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9773127b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9667bf9",
   "metadata": {},
   "source": [
    "## 02.1 - Treinando & Validando o Load-v1\n",
    "Bem, no **load-v1** foi passado para a etapa de **treinamento & validação** a coluna (feature) **\"Title\"**. Ou seja, nós vamos ter as seguintes variáveis (features) para os nossos modelos:\n",
    "\n",
    " - **Variáveis Independente:**\n",
    "   - Title *(com CountVectorizer):*\n",
    "     - stop_words=\"english\"\n",
    "     - max_df=0.60 (Ignores terms that appear in MORE than 60% of documents)\n",
    "     - min_df=0.05 (Ignores terms that appear in LESS than 5% of documents)\n",
    " - **Variáveis Dependente:**\n",
    "   - SalaryNormalized (normalizada pelo a Adzuna)\n",
    "\n",
    "**NOTE:**  \n",
    "Esse vai ser o nosso **baseline model**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c3e39d",
   "metadata": {},
   "source": [
    "**Pegando a variável dependente (target=y):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e8b773e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File extracted!\n"
     ]
    }
   ],
   "source": [
    "# Extract training set.\n",
    "preprocessing.extract_7z_data(\"../datasets/Train_rev1.7z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70a6d47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data ready!\n"
     ]
    }
   ],
   "source": [
    "df_training = preprocessing.get_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ab5690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_training[\"SalaryNormalized\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f599790",
   "metadata": {},
   "source": [
    "**Pegando a variável Independente (X):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbf74fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "df_title_vectorized = scipy.sparse.load_npz('../resources/processed_features/df_title_train_vectorized.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd26a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_title_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26a2364",
   "metadata": {},
   "source": [
    "**Dividindo os dados em *dados de treino* e *dados de validação*:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e7adc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = training.split_data(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a88907a",
   "metadata": {},
   "source": [
    "**Testando a Métrica de validação MAE com Validação-Cruzada K-Fold**  \n",
    "Agora vamos testar nossa **Métrica de Validação MAE (Mean Absolute Error)** para cada algoritmo, porém, utilizando uma **Validação-Cruzada** com **K-Fold**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae3fa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "training.get_mae_scores(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19257ea3",
   "metadata": {},
   "source": [
    "**NOTE:**  \n",
    "Bem, para esse conjunto de dados o modelo que teve a melhor performance (MAE) foi o **Random Forest Regressor**.\n",
    "\n",
    "**NOTE:**  \n",
    "Agora vamos fazer algumas predições com esse modelo, porém, nos dados de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7398b18b",
   "metadata": {},
   "source": [
    "**Pegando a variável independente (X) de teste:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e02e85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "df_title_test_vectorized = scipy.sparse.load_npz('../resources/processed_features/df_title_test_vectorized.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d530f9",
   "metadata": {},
   "source": [
    "**Fazendo previsões para os dados de teste:**  \n",
    "Para fazer previsões com os dados de teste nós devemos passar:\n",
    " - x_train;\n",
    " - y_train;\n",
    " - x_test (ou seja, feature que nós pré-processamos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16629bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries_predicted = training.random_forest_regressor(x_train, y_train, df_title_test_vectorized, predict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e411aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f2851e",
   "metadata": {},
   "source": [
    "**Criando Learning Curves (ou Curvas de Aprendizado):**  \n",
    "Ok, nós já escolhemos o modelo que teve a melhor performance para a métrica **MAE**, fizemos previsões com os dados de teste para esse modelo. Agora vem a ***pergunta chave***:\n",
    "\n",
    "> Qual a Taxa de erro para os dados de treino e os dados de validação para esse modelo?\n",
    "\n",
    "Para isso nós vamos utilizar o método **create_learning_curves()** que nós criamos na classe **Training**, respondável por retornar estatísticas de erros de um modelo X (RandomForestRegressor no nosso caso).\n",
    "\n",
    "Vamos passar como argumento para o método **create_learning_curves()**:\n",
    " - x_train;\n",
    " - y_train;\n",
    " - Estimator:\n",
    "   - O modelo que nós escolhemos.\n",
    " - save (opcional):\n",
    "   - Nome para o plot() criado, esse nome vai ser usado para salvar a imagem em: *resources/load*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51ea902",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training.create_learning_curves(x=x_train, y=y_train, estimator=RandomForestRegressor, cv=10, save=\"learning-curve-load-01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0beea4",
   "metadata": {},
   "source": [
    "Olhando para as estatísticas acima, nós temos o seguinte:\n",
    " - **train_sizes: O tamanho do nosso \"train_sizes\" vai depender do tamanho do Cross-Validaton. Como eu passei cv=10 o nosso \"train_sizes\" vai ser em 10 conjuntos diferentes:**\n",
    "   - train_sizes:  [    1   334   669  1338  2677  5354 10708 21417 42834 85668]\n",
    "   - A lógica de criação dos conjuntos foi a seguinte:\n",
    "     - Inicia com 1 ... até ... o número de instâncias dividido por 2 e vai dividindo até chegar em cv-1.\n",
    " - **training scores: Nos erros de treino nós tivemos a seguinte situação:**\n",
    "   - Quanto tivemos apenas uma instância o erro foi claro (claro, o algoritmo de ajustou perfeitamente).\n",
    "   - O erro máximo no conjunto de treinamento foi de **2.72**.\n",
    " - **validation scores: Nos erros de treino nós tivemos a seguinte situação:**\n",
    "   - Obviamente, quando tinhamos apenas uma instância nos dados de treino o erro de validação foi o maior 4.1, visto que o Algoritmo não generalizou (aprendeu) suficiente.\n",
    "   - O erro mínimo foi 2.72 com 85.668 instâncias.\n",
    " - **Observações gerais:**\n",
    "   - A partir de 20.000 instâncias os erros convergem e ficam sempre entre **2.69** e **2.72**:\n",
    "     - Ou seja, não adianta adicionar mais instâncias a partir desse ponto que o algoritmo provavelmente não vai performar melhor.\n",
    "     - Uma abordagem para melhorar (tentar resolver) esse problema será aumentar a complexidade do modelo (por exemplo, adicionando ou melhorando alguma feature).\n",
    "     - Outra observação importante é que temos uma baixa variância, pois o **gap (lacuna)** entre os dois erros é muito pequeno:\n",
    "       - Geralmente, quanto mais estreita a lacuna (gap), menor a variância;\n",
    "       - O oposto também é verdadeiro: quanto maior a diferença da lacuna (gap), maior a variância"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6af7cca",
   "metadata": {},
   "source": [
    "**Salvando o load-v1:**  \n",
    "Por fim, agora vamos salvar o nosso **load-v1** que vai ser:\n",
    " - O modelo que teve melhor performance (Random Forest Regresso);\n",
    " - As predições desse modelo para os dados de teste.\n",
    "\n",
    "**NOTE:**  \n",
    "Para salvar o modelo, para cada implementações eu criei um \"mecanismo\", onde só é passar o nome *(model_name)* do modelo que ele já vai salvar automaticamente. Lembrando, também que não vamos passar o argumento **\"predict=True\"** e como por default ele é *False*, nenhuma predição será feitas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea26b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training.random_forest_regressor(x_train, y_train, df_title_test_vectorized, model_name=\"model-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435ef38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.save_to_csv(df=salaries_predicted, df_name=\"test-predict-load-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdf5226",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46d2680",
   "metadata": {},
   "source": [
    "# Resumos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cf339d",
   "metadata": {},
   "source": [
    " - **No *Load-v1* nós tinhamos as seguintes situações:**\n",
    "   - Variáveis (features):\n",
    "     - Independentes:\n",
    "       - Title *(com CountVectorizer):*\n",
    "         - stop_words=\"english\"\n",
    "         - max_df=0.60 (Ignores terms that appear in MORE than 60% of documents)\n",
    "         - min_df=0.05 (Ignores terms that appear in LESS than 5% of documents)\n",
    "     - Dependente:\n",
    "       - SalaryNormalized (normalizada pelo a Adzuna)\n",
    "   - *Como Métrica de Avaliação (MAE) tivemos os seguintes resultados:*\n",
    "     - MAE for Random Forest Regressor: 12071.796335062201\n",
    "     - MAE for Linear Regression: 12218.362466385533\n",
    "     - MAE for Ridge (L2) Regression: 13111.77715114541\n",
    "     - MAE for Lasso (L1) Regression: 12218.562226956381\n",
    "     - MAE for Elastic Net (L2 + L1) Regression: 12218.559539523578\n",
    "     - The best model is randomForestRegressor with MAE value: 12071.796335062201\n",
    "   - *Learning Curves:*\n",
    "     - *training scores: Nos erros de treino nós tivemos a seguinte situação:*\n",
    "       - Quanto tivemos apenas uma instância o erro foi claro (claro, o algoritmo de ajustou perfeitamente).\n",
    "       - O erro máximo no conjunto de treinamento foi de **2.72**.\n",
    "     - *validation scores: Nos erros de treino nós tivemos a seguinte situação:*\n",
    "       - Obviamente, quando tinhamos apenas uma instância nos dados de treino o erro de validação foi o maior 4.1, visto que o Algoritmo não generalizou (aprendeu) suficiente.\n",
    "       - O erro mínimo foi 2.72 com 85.668 instâncias.\n",
    "     - *Observações gerais:*\n",
    "       - A partir de 20.000 instâncias os erros convergem e ficam sempre entre 2.69 e 2.72:\n",
    "         - Ou seja, não adianta adicionar mais instâncias a partir desse ponto que o algoritmo provavelmente não vai performar melhor.\n",
    "         - Uma abordagem para melhorar (tentar resolver) esse problema será aumentar a complexidade do modelo (por exemplo, adicionando ou melhorando alguma feature).\n",
    "         - Outra observação importante é que temos uma baixa variância, pois o gap (lacuna) entre os dois erros é muito pequeno:\n",
    "           - Geralmente, quanto mais estreita a lacuna (gap), menor a variância;\n",
    "           - O oposto também é verdadeiro: quanto maior a diferença da lacuna (gap), maior a variância"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf3d4c3",
   "metadata": {},
   "source": [
    "**Rodrigo Leite -** *drigols*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
